{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72ac70f6-5840-4649-94a9-0b589eede30c",
   "metadata": {},
   "source": [
    "<!-- Trabalho Desenvolvido no Curso da Data Science Academy - www.datascienceacademy.com.br -->\n",
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Fundamentos de Linguagem Python - Do Básico a Aplicações de IA</font>\n",
    "# <font color='blue'>Mini-Projeto 6</font>\n",
    "# <font color='blue'>Modelo de Classificação Para Análise de Sentimentos</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2194240c-4b9c-430e-a7df-c63e5b94a0cd",
   "metadata": {},
   "source": [
    "## 1. Definição do Problema de Negócio\n",
    "\n",
    "É a fundação do projeto. Nesta etapa, traduzimos uma necessidade da empresa em um objetivo claro para a Ciência de Dados. Definimos o que queremos resolver (automatizar a classificação de reviews de produtos, por exemplo), por que é importante (reduzir custos, agilizar a tomada de decisão) e como o sucesso será medido.\n",
    "\n",
    "**Definição:**\n",
    "\n",
    "Uma empresa de e-commerce deseja automatizar a análise de feedback de seus clientes. Atualmente, a análise é feita manualmente, o que é um processo lento, caro e que não escala com o volume de reviews recebidos diariamente.\n",
    "\n",
    "**Objetivo:** \n",
    "\n",
    "Criar um modelo de Machine Learning que classifique automaticamente os reviews de produtos como **'positivo'** ou **'negativo'**.\n",
    "\n",
    "**Benefícios Esperados:**\n",
    "* **Eficiência:** Reduzir o tempo e o custo da análise de feedback.\n",
    "* **Tomada de Decisão Rápida:** Permitir que as equipes de produto e marketing identifiquem rapidamente produtos com problemas ou oportunidades de melhoria.\n",
    "* **Priorização:** Direcionar reviews negativos para a equipe de suporte ao cliente de forma prioritária, melhorando a experiência do consumidor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bea8d1-2067-481a-8544-b61f47524e6b",
   "metadata": {},
   "source": [
    "## 2. Importação dos Pacotes\n",
    "\n",
    "Esta é a fase de preparação do ambiente de trabalho. Aqui, carregamos todas as ferramentas e bibliotecas Python necessárias (como Pandas para manipulação de dados, Scikit-learn para modelagem e Matplotlib/Seaborn para visualizações) que serão utilizadas ao longo do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e23e9095-119c-47ae-8ed8-1c093b0e85de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Instala o pacote watermark\n",
    "\n",
    "%pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea114251-86f1-4615-b5c1-b7d6841bf3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulação de dados e visualização\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pré-Processamento e Machine Learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e02072-be01-409b-a2db-364eb2eccd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações de visualização\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d1810-38f4-4b6e-913c-90e2eca5630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62932c7b-c0f7-4ddb-b856-e599e9484b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bb7e68-c004-463d-b3e3-6ec0aef57324",
   "metadata": {},
   "source": [
    "## 3. Carregando e Compreendendo os Dados\n",
    "\n",
    "É o primeiro contato com a matéria-prima do projeto. Lemos os dados de uma fonte (no nosso caso, um arquivo CSV) para um DataFrame do Pandas e realizamos uma verificação inicial para entender sua estrutura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23978785-ff03-40e3-95f9-ba8f17e48e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o nome do arquivo\n",
    "nome_arquivo_csv = 'dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ad7c93-4f9a-40bf-a95e-0c95d8ebed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset\n",
    "df_dsa = pd.read_csv(nome_arquivo_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cc6f38-3723-4b5b-8bcf-ff3b4e063cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape\n",
    "df_dsa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808393e2-27fb-4492-982d-6ced9cfcf2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiras linhas\n",
    "df_dsa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c20dec-b284-417c-944e-732499992b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amostra dos dados\n",
    "df_dsa.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0202171-ee61-40c7-af85-9071fa81f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Últimas linhas\n",
    "df_dsa.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1569901-b90e-4b0e-ab0b-2602ccdb969b",
   "metadata": {},
   "source": [
    "## 4. Análise Exploratória de Dados (EDA)\n",
    "\n",
    "A fase de investigação. Aqui, \"mergulhamos\" nos dados para descobrir padrões, anomalias e insights. Utilizamos gráficos (como a contagem de sentimentos positivos vs. negativos) e estatísticas para entender a distribuição e as características dos dados antes de qualquer modificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55831404-0ea6-441c-97e2-895ff3a1f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info\n",
    "df_dsa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf83f539-5d35-4310-8560-7731e467440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nVerificando valores ausentes:\\n\")\n",
    "print(df_dsa.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029058cd-3d07-43b6-b140-90cb32e564e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDistribuição dos Sentimentos:\\n\")\n",
    "sns.countplot(x = 'sentimento', data = df_dsa)\n",
    "plt.title('Distribuição das Classes de Sentimento')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d23b37-6f69-436c-a80e-10cedf91f7a4",
   "metadata": {},
   "source": [
    "## 5. Limpeza de Dados\n",
    "\n",
    "Nesta etapa corrigimos os problemas identificados na EDA. Isso inclui tratar valores ausentes (por exemplo, removendo as linhas correspondentes), garantir que os dados estejam no formato correto e aplicar a função de limpeza de texto (dsa_limpa_texto) para normalizar os reviews, removendo acentos, pontuações e caracteres indesejados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b7320d-1183-4b20-9b08-a6f1cf84ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover linhas com valores ausentes\n",
    "print(f\"\\nTamanho original do DataFrame: {len(df_dsa)}\")\n",
    "df_dsa.dropna(subset = ['texto_review'], inplace = True)\n",
    "print(f\"Tamanho do DataFrame após remover nulos: {len(df_dsa)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6457f11-f98f-4b57-a6da-65b49319abbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a8f665-fc55-49e9-81a0-483829f5f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ea50c7-2f41-4927-8bdd-8cb9750108ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de limpeza de texto \n",
    "def dsa_limpa_texto(texto):\n",
    "    \n",
    "    \"\"\"\n",
    "    Função completa de limpeza de texto:\n",
    "    1. Converte para minúsculas.\n",
    "    2. Remove acentos e cedilha.\n",
    "    3. Remove pontuações, números e caracteres especiais.\n",
    "    4. Remove espaços extras.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Garante que o texto não seja nulo (caso haja algum NaN no DataFrame)\n",
    "    if not isinstance(texto, str):\n",
    "        return \"\"\n",
    "\n",
    "    # --- PASSO 1: Normalizar e remover acentos ---\n",
    "    # Normaliza para a forma 'NFKD' que separa o caractere da acentuação\n",
    "    # e depois remove os acentos (Nonspacing Mark)\n",
    "    texto_sem_acentos = ''.join(c for c in unicodedata.normalize('NFKD', texto) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "    # --- PASSO 2: Limpeza com Regex ---\n",
    "    # Converter para minúsculas\n",
    "    texto_limpo = texto_sem_acentos.lower()\n",
    "    \n",
    "    # Manter apenas letras e espaços. A remoção de acentos já foi feita.\n",
    "    texto_limpo = re.sub(r'[^a-z\\s]', '', texto_limpo)\n",
    "    \n",
    "    # Remover espaços extras\n",
    "    texto_limpo = re.sub(r'\\s+', ' ', texto_limpo).strip()\n",
    "    \n",
    "    return texto_limpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ff55d6-736d-4246-998c-edefabf70c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a função de limpeza\n",
    "df_dsa['texto_limpo'] = df_dsa['texto_review'].apply(dsa_limpa_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5788c19-fef2-4a2a-bb19-44533719ebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d30cb6-f540-4bce-9049-4326ba18cae9",
   "metadata": {},
   "source": [
    "https://docs.python.org/3/library/re.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729f5899-16c2-4c9c-a1d9-1a793df6991d",
   "metadata": {},
   "source": [
    "## 6. Engenharia de Atributos\n",
    "\n",
    "É a etapa onde transformamos dados brutos em \"features\" (atributos) úteis para o modelo. No nosso projeto, isso envolveu a criação da coluna texto_limpo e, mais importante, a conversão das classes de texto ('positivo', 'negativo') em um formato numérico (sentimento_label: 1, 0), que é o que o algoritmo de Machine Learning consegue entender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1401d2-3bc6-4bc7-ab7d-ab99dc55960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400e4441-8f80-4e39-b6f8-b1960f1447a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapear o sentimento para valores numéricos (Engenharia de Atributos)\n",
    "df_dsa['sentimento_label'] = df_dsa['sentimento'].map({'positivo': 1, 'negativo': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409c5469-1ba3-4496-aa13-34ebfd7120d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDataFrame após a limpeza e mapeamento:\\n\")\n",
    "df_dsa[['texto_limpo', 'sentimento_label']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d4582a-94d1-4361-856d-74201abe8fd2",
   "metadata": {},
   "source": [
    "## 7. Divisão em Dados de Treino de Teste\n",
    "\n",
    "Um passo essencial para treinamento e avaliação do modelo. Separamos o conjunto de dados em duas partes: uma maior (treino), que o modelo usará para aprender, e uma menor (teste), que será mantida \"escondida\" do modelo para simular dados novos e avaliar sua real performance após o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c1ac3d-ee4c-4e0f-9614-35e1871cce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir variáveis X (entrada) e y (saída)\n",
    "X = df_dsa['texto_limpo']\n",
    "y = df_dsa['sentimento_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea4530-14b7-4658-8ced-b3ea68345f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir os dados em treino e teste\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size = 0.25, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288a0c4d-bf4c-42eb-913f-2bf9fca299c2",
   "metadata": {},
   "source": [
    "## 8. Pipeline de Modelagem Preditiva\n",
    "\n",
    "Aqui, construímos uma esteira de produção automatizada para o nosso modelo. O Pipeline do Scikit-learn encapsula todas as etapas de pré-processamento (vetorização TF-IDF, padronização com StandardScaler) e o modelo final (Regressão Logística), garantindo que os mesmos passos sejam aplicados de forma consistente nos dados de treino e nos novos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bb457d-ab71-46a0-b90d-c5ff32d4719d",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b619d5-fc03-4bc7-bd4f-1aaffdca0df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline \n",
    "pipeline = Pipeline([\n",
    "    \n",
    "    ('tfidf', TfidfVectorizer(stop_words = ['de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um'])),\n",
    "    \n",
    "    ('scaler', StandardScaler(with_mean = False)),\n",
    "    \n",
    "    ('logreg', LogisticRegression(solver = 'liblinear', random_state = 42, max_iter = 1000)) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61bf973-ad59-4d80-adff-b76b35daff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5266d4-dcc8-4f8b-803a-d81157fdc78d",
   "metadata": {},
   "source": [
    "O pipeline é composto por três etapas sequenciais, cada uma com um nome ('tfidf', 'scaler', 'logreg') e uma função específica.\n",
    "\n",
    "### 8.1. Vetorização dos Dados de Texto ('tfidf', TfidfVectorizer(...))\n",
    "\n",
    "O que faz? Esta é a primeira etapa, chamada 'tfidf'. Ela usa o TfidfVectorizer para converter o texto bruto em números. Ele transforma cada review em um vetor numérico, onde cada número representa a importância de uma palavra naquele texto em relação a todos os outros textos. Palavras comuns como 'de', 'a', 'o', etc., são ignoradas (stop_words).\n",
    "\n",
    "### 8.2. Padronização de Dados ('scaler', StandardScaler(with_mean=False))\n",
    "\n",
    "O que faz? A segunda etapa, 'scaler', pega os vetores numéricos criados pela etapa anterior e os padroniza. O StandardScaler ajusta a escala de todos os números para que tenham uma variância semelhante. O parâmetro with_mean=False é essencial aqui, pois a matriz de dados do TF-IDF é \"esparsa\" (cheia de zeros), e essa opção preserva essa característica, evitando problemas de memória e computação.\n",
    "\n",
    "### 8.3. Modelo de Machine Learning ('logreg', LogisticRegression(...))\n",
    "\n",
    "O que faz? A etapa final, 'logreg', é o modelo de classificação em si. A LogisticRegression recebe os dados numéricos, já padronizados, e aprende a fazer a previsão final: classificar o texto como \"positivo\" ou \"negativo\".\n",
    "\n",
    "\n",
    "O grande benefício do pipeline é a automação e a consistência. Ao treinar este pipeline, ele aprende a fazer todas as três coisas. Depois, quando você apresenta um novo texto para ele prever, o pipeline automaticamente executa a mesma sequência exata de vetorização, padronização e classificação, garantindo que não haja erros no pré-processamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11694b3d-41ff-4f79-9454-c7bc5cbcaa8a",
   "metadata": {},
   "source": [
    "### 8.4. Otimização de Hiperparâmetros\n",
    "\n",
    "É o ajuste fino do modelo. Usando GridSearchCV, testamos sistematicamente várias combinações de configurações (hiperparâmetros) para o pipeline, a fim de encontrar a combinação que resulta na melhor performance possível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c7177-b480-452a-8dc2-90f2a090f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o grid de hiperparâmetros para otimização\n",
    "parametros_grid = {\n",
    "    'tfidf__max_features': [500, 1000, 2000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'logreg__C': [0.1, 1, 10],\n",
    "    'logreg__penalty': ['l1', 'l2'],\n",
    "    'logreg__max_iter': [5000, 6000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90c947a-97c9-4910-8a25-37cf4aea3964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar o GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,              # Pipeline com as etapas de pré-processamento e modelo\n",
    "    parametros_grid,       # Dicionário com as combinações de hiperparâmetros a serem testadas\n",
    "    cv = 5,                # Número de divisões para validação cruzada (5-fold cross-validation)\n",
    "    n_jobs = -1,           # Usa todos os núcleos disponíveis do processador para acelerar o processo\n",
    "    scoring = 'accuracy',  # Métrica usada para avaliar o desempenho de cada combinação (aqui, acurácia)\n",
    "    verbose = 1            # Nível de detalhamento do output durante a execução (1 exibe progresso básico)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fb7be6-0996-4680-a5f9-fa71f0f2aafe",
   "metadata": {},
   "source": [
    "Validação cruzada é uma técnica usada para avaliar o desempenho de um modelo dividindo o conjunto de dados em várias partes (ou “folds”). O modelo é treinado em algumas dessas partes e testado em outras, de forma rotativa. Isso permite medir o desempenho de forma mais confiável e geral, evitando que o resultado dependa apenas de uma única divisão dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e062954-da73-4673-a9c5-802abe671272",
   "metadata": {},
   "source": [
    "### 8.5. Treinamento do Modelo\n",
    "\n",
    "Nesta etapa, alimentamos o pipeline com os dados de treino. O GridSearchCV executa o processo de .fit(), onde o algoritmo aprende os padrões que conectam o texto dos reviews aos seus respectivos sentimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9348b5aa-9497-479c-9450-51a7947ea345",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nIniciando o treinamento do modelo com otimização de hiperparâmetros...\\n\")\n",
    "grid_search.fit(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ed00c-423e-45a5-9faf-2a923ad8825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMelhores hiperparâmetros encontrados:\\n\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22116c0-aebb-402e-9a30-0d0fd12ca4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter o melhor modelo\n",
    "melhor_modelo_dsa = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cbb1d7-af26-4e78-96ab-f3977f2d7d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(melhor_modelo_dsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ba8e05-9ab0-43c3-bf8d-c2798f1b7f40",
   "metadata": {},
   "source": [
    "## 9. Avaliação do Modelo e Interpretação de Métricas\n",
    "\n",
    "É a \"prova final\". Usamos o conjunto de teste (os dados que o modelo nunca viu) para fazer previsões e compará-las com os resultados reais. Métricas como Acurácia, Relatório de Classificação e a Matriz de Confusão nos dizem quão bem o modelo está generalizando e se ele atende aos objetivos de negócio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e30e8c-1a03-4851-baff-4dd0c744e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões no conjunto de teste\n",
    "y_pred = melhor_modelo_dsa.predict(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675dfd79-350d-43d2-8073-02a5d3d0550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular as métricas de avaliação\n",
    "acuracia = accuracy_score(y_teste, y_pred)\n",
    "report = classification_report(y_teste, y_pred, target_names = ['Negativo', 'Positivo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceaf787-f73c-4b4b-ac2b-4703c555806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nAcurácia do Modelo: {acuracia:.2%}\\n\")\n",
    "print(\"Relatório de Classificação:\\n\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b968c1a-2102-455b-a815-d217906f6458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar a Matriz de Confusão\n",
    "cm = confusion_matrix(y_teste, y_pred)\n",
    "sns.heatmap(cm, annot = True, fmt = 'd', cmap = 'Blues',\n",
    "            xticklabels = ['Negativo', 'Positivo'],\n",
    "            yticklabels = ['Negativo', 'Positivo'])\n",
    "plt.xlabel('Previsão')\n",
    "plt.ylabel('Verdadeiro')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64221360-cb7b-47c3-b9dd-d94c5dd5db52",
   "metadata": {},
   "source": [
    "**1. Acurácia (Accuracy)**\n",
    "\n",
    "De todos os reviews (positivos e negativos) que o modelo analisou, qual a porcentagem total de acertos?\n",
    "\n",
    "Em nosso contexto: Se você passou 100 reviews pelo modelo e ele acertou a classificação de 92 deles (independentemente de serem positivos ou negativos), a acurácia é de 92%. É a medida mais geral de performance.\n",
    "\n",
    "**2. Precisão (Precision)**\n",
    "\n",
    "Esta métrica é calculada para cada classe.\n",
    "\n",
    "Precisão para a classe 'Positivo': Dos reviews que o modelo rotulou como 'Positivos', quantos eram realmente Positivos?\n",
    "\n",
    "Em nosso contexto: Se o modelo marcou 10 reviews como \"Positivos\", mas apenas 9 deles eram de fato positivos (e 1 era um erro, um falso positivo), a precisão para a classe 'Positivo' é de 90%.\n",
    "\n",
    "Importância: Uma alta precisão aqui significa que você pode confiar na etiqueta \"Positivo\". Se você for usar esses reviews em um material de marketing, por exemplo, não quer mostrar acidentalmente um review negativo.\n",
    "\n",
    "Precisão para a classe 'Negativo': Dos reviews que o modelo rotulou como 'Negativos', quantos eram realmente Negativos?\n",
    "\n",
    "Em nosso contexto: Se o modelo marcou 10 reviews como \"Negativos\" e todos os 10 eram de fato negativos, a precisão para a classe 'Negativo' é de 100%.\n",
    "\n",
    "Importância: Essencial para a equipe de suporte. Uma alta precisão aqui garante que o tempo da equipe não seja gasto analisando reviews que na verdade eram positivos (falsos negativos para o time de suporte).\n",
    "\n",
    "**3. Recall**\n",
    "\n",
    "Esta métrica também é calculada para cada classe.\n",
    "\n",
    "Recall para a classe 'Positivo': De todos os reviews que realmente eram Positivos, quantos o seu modelo conseguiu encontrar?\n",
    "\n",
    "Em nosso contexto: Se existiam 12 reviews positivos no total, mas o seu modelo só conseguiu identificar 9 deles (deixando 3 passarem despercebidos), o recall para a classe 'Positivo' é de 75% (9 de 12).\n",
    "\n",
    "Importância: Um alto recall aqui garante que você está capturando a maior parte do feedback positivo. Você não está perdendo a oportunidade de identificar clientes satisfeitos.\n",
    "\n",
    "Recall para a classe 'Negativo': De todos os reviews que realmente eram Negativos, quantos o seu modelo conseguiu encontrar?\n",
    "\n",
    "Em nosso contexto: Se existiam 10 clientes insatisfeitos (reviews negativos), e o modelo identificou 9 deles, o recall para 'Negativo' é de 90%. Ele \"deixou escapar\" um cliente insatisfeito.\n",
    "\n",
    "Importância: Talvez a métrica mais crítica para a gestão de crises. Um alto recall para 'Negativo' é vital para garantir que quase nenhuma reclamação passe despercebida e que a equipe de suporte possa agir.\n",
    "\n",
    "**4. F1-Score**\n",
    "\n",
    "Qual é o balanço equilibrado entre a Precisão e o Recall para cada classe?\n",
    "\n",
    "Em nosso contexto: É uma única nota que combina as duas métricas anteriores. O F1-Score para a classe 'Positivo' só será alto se tanto a precisão quanto o recall para 'Positivo' forem altos. Ele evita o cenário onde um modelo é ótimo em uma métrica, mas péssimo em outra. É frequentemente a melhor métrica para avaliar a performance do modelo em uma classe específica.\n",
    "\n",
    "**5. Support (Suporte)**\n",
    "\n",
    "Quantos reviews de cada classe realmente existiam no meu conjunto de teste?\n",
    "\n",
    "Em nosso contexto: Se o relatório mostra um support de 58 para 'Positivo' e 62 para 'Negativo', significa que no seu conjunto de dados de teste havia 58 reviews positivos e 62 negativos.\n",
    "\n",
    "Importância: Dá contexto aos resultados. Se o support de uma classe for muito baixo, as métricas de performance para essa classe são menos confiáveis, pois foram calculadas com base em poucos exemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0d2a0a-4953-4a44-b36f-114e71aa7c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se estivermos satisfeitos com a performance do modelo, salvamos em disco\n",
    "joblib.dump(melhor_modelo_dsa, 'modelo_sentimento_dsa_v1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9a357c-0222-4479-8caf-06116ca2ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pode deletar o modelo treinado e removê-lo da memória\n",
    "del melhor_modelo_dsa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f2fc0-473a-4109-a81a-c1eb1d36a839",
   "metadata": {},
   "source": [
    "**Nota: Normalmente aqui termina o trabalho de um Cientista de Dados. A etapa a seguir é, normalmente, responsabilidade de um Engenheiro de Machine Learning.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfa6c1d-c5cc-4abf-beb2-36b35cabbbda",
   "metadata": {},
   "source": [
    "## 10. MLOps, Deploy e Uso do Modelo\n",
    "\n",
    "A etapa final, onde o modelo começa a gerar valor real. \"Deploy\" significa colocar o modelo treinado em produção. No nosso caso, simulamos isso criando a função dsa_prever_sentimento, que encapsula o pipeline treinado e pode ser usada para classificar novos reviews de forma rápida e automática.\n",
    "\n",
    "Leia sobre MLOps no Capítulo 11 do curso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225a54d-49be-4b45-9485-89407fddf4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo a partir do disco\n",
    "modelo_dsa_deploy = joblib.load('modelo_sentimento_dsa_v1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ebdf43-6bd6-444b-9ea8-9f5318276595",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(modelo_dsa_deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24d28a4-513c-422b-8d10-90556f763f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar novos dados para simular o uso em produção\n",
    "novos_reviews = [\n",
    "    \"A bateria do celular não dura nada, péssima compra.\",\n",
    "    \"Chegou antes do prazo e o produto é de ótima qualidade! Estou muito feliz.\",\n",
    "    \"O serviço de atendimento foi rápido e eficiente.\",\n",
    "    \"Não recomendo, veio faltando peças e a cor estava errada.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15469622-46ce-43c5-bfe3-52ad07df2532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para prever o sentimento de novos reviews \n",
    "def dsa_prever_sentimento(reviews):\n",
    "    \n",
    "    \"\"\"\n",
    "    Recebe uma lista de textos de review e retorna a previsão de sentimento.\n",
    "    O objeto 'melhor_modelo_dsa' (pipeline) cuida de todos os passos internos.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 'reviews' entra no pipeline\n",
    "    # 2. TF-IDF é aplicado internamente\n",
    "    # 3. StandardScaler é aplicado internamente\n",
    "    # 4. LogisticRegression faz a previsão\n",
    "    previsoes = modelo_dsa_deploy.predict(reviews)\n",
    "    \n",
    "    # Mapeia o resultado numérico de volta para texto\n",
    "    sentimentos = ['Negativo' if p == 0 else 'Positivo' for p in previsoes]\n",
    "    \n",
    "    # Exibe os resultados\n",
    "    for review, sentimento in zip(reviews, sentimentos):\n",
    "        print(f\"\\nReview: '{review}'\\nSentimento Previsto: {sentimento}\\n---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd895687-2714-4ca7-81b3-606ac77ee5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar a função de deploy com os novos dados\n",
    "print(\"\\n--- Iniciando Classificação de Novos Reviews (Deploy com Pipeline Completo) ---\\n\")\n",
    "dsa_prever_sentimento(novos_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bef2647-e545-4a06-8922-b7c8e40456c6",
   "metadata": {},
   "source": [
    "**Projeto concluído, projeto entregue, cliente feliz, partimos para o próximo projeto! :-)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e70e92c-24ab-4d41-8362-89841f80232f",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
